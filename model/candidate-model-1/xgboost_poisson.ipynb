{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data\n",
    "final_result = pd.read_csv('processed_incident_count_005.csv')\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for i in range(505):\n",
    "    path = f\"/Users/pei/Desktop/Pei/Research/RA role in University/utd_prof_ding/zDPD_data_0-10999999/zDPD_data_{1999+i*2000}.csv\"\n",
    "    df = pd.concat([df, pd.read_csv(path).iloc[:,1:]])\n",
    "print(df.shape)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lon_bin'] = df['lon_bin'].round(2)\n",
    "df['lat_bin'] = df['lat_bin'].round(2)\n",
    "final_result['date'] = final_result['date'].apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "df = df.merge(final_result, how = \"left\", \n",
    "              left_on = ['lon_bin', 'lat_bin', 'date'], right_on = ['lon_bin', 'lat_bin', 'date'],\n",
    "              suffixes=['_drop', ''])\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "# Ensure the data is sorted by date\n",
    "df = df.sort_values(by='date')\n",
    "# Assuming df['date'] contains datetime objects\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Extract year, day of year, week of year, and month-day components\n",
    "df['date_year'] = df['date'].dt.year\n",
    "df['day_of_year'] = df['date'].dt.dayofyear\n",
    "df['week_of_year'] = df['date'].dt.isocalendar().week\n",
    "\n",
    "# Encode day_of_year cyclically\n",
    "df['day_of_year_sin'] = np.sin(2 * np.pi * df['day_of_year'] / 365)\n",
    "df['day_of_year_cos'] = np.cos(2 * np.pi * df['day_of_year'] / 365)\n",
    "\n",
    "# Encode week_of_year cyclically\n",
    "df['week_of_year_sin'] = np.sin(2 * np.pi * df['week_of_year'] / 52)\n",
    "df['week_of_year_cos'] = np.cos(2 * np.pi * df['week_of_year'] / 52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "features = ['lon_bin', 'lat_bin', 'date_year', 'day_of_year_sin', 'day_of_year_cos', 'week_of_year_sin', 'week_of_year_cos',\n",
    "            'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'Unemployment_Rate(%)', 'Unemployment_Rank', 'CPI(Annual)']\n",
    "target = 'unique_event_count'\n",
    "\n",
    "# Train-test split\n",
    "train_data = df[df['date'] < '2024-01-01']  # Train on data before 2023\n",
    "test_data = df[df['date'] >= '2024-01-01']  # Test on data from 2023 onward\n",
    "\n",
    "# Convert training data to DMatrix for XGBoost\n",
    "dtrain = xgb.DMatrix(train_data[features], label=train_data[target])\n",
    "\n",
    "\n",
    "# poisson_obj for event count prediction assuming the count follow poisson distribution\n",
    "def poisson_obj(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    preds = np.exp(preds)  # Ensure predictions are positive\n",
    "    grad = preds - labels  # Gradient: difference between prediction and true count\n",
    "    hess = preds           # Hessian: prediction values (positive)\n",
    "    return grad, hess\n",
    "\n",
    "\n",
    "# Set XGBoost parameters\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'max_depth': 6,\n",
    "    'eta': 0.01,  # Learning rate\n",
    "    'eval_metric': 'rmse',\n",
    "    'scale_pos_weight': 10\n",
    "}\n",
    "\n",
    "\n",
    "# Train initial model\n",
    "model = xgb.train(params, dtrain, num_boost_round=100, obj=poisson_obj)\n",
    "\n",
    "# Group test data by date\n",
    "test_dates = sorted(test_data['date'].unique())  # Get unique dates in the test set\n",
    "\n",
    "# Rolling evaluation with incremental updates\n",
    "errors = []  # To store RMSE for each day\n",
    "predictions = []\n",
    "for test_date in test_dates:\n",
    "    # Get all rows for the current test date\n",
    "    test_day = test_data[test_data['date'] == test_date]\n",
    "    \n",
    "    # Create a DMatrix for the test day's data\n",
    "    dtest = xgb.DMatrix(test_day[features])\n",
    "    y_test = test_day[target].values  # True values for all locations on the current day\n",
    "    \n",
    "    # Predict for the test day's data\n",
    "    y_pred = model.predict(dtest)\n",
    "    \n",
    "    # Transform predictions back to original scale\n",
    "    y_pred_exp = np.exp(y_pred)  # Apply exponential transformation\n",
    "    \n",
    "    # Enforce integer predictions\n",
    "    y_pred_rounded = np.round(y_pred_exp).astype(int)\n",
    "    \n",
    "    # Ensure non-negative predictions\n",
    "    y_pred_rounded = np.clip(y_pred_rounded, 0, None)\n",
    "\n",
    "    # Calculate RMSE for the day\n",
    "    rmse = np.sqrt(np.mean((y_test - y_pred_rounded) ** 2))\n",
    "    errors.append(rmse)\n",
    "    predictions.extend(y_pred_rounded)\n",
    "    \n",
    "    # Update the model with the test day's data\n",
    "    dnew = xgb.DMatrix(test_day[features], label=test_day[target])\n",
    "    model = xgb.train(params, xgb.DMatrix(pd.concat([train_data[features], test_day[features]]), \n",
    "                                          label=pd.concat([train_data[target], test_day[target]])),\n",
    "                      obj=poisson_obj)\n",
    "    \n",
    "    # Optional: Add the test day's data to the training dataset\n",
    "    train_data = pd.concat([train_data, test_day])\n",
    "\n",
    "# Overall evaluation\n",
    "overall_rmse = np.mean(errors)\n",
    "print(f\"Overall RMSE: {overall_rmse}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
